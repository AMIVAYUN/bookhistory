# Chapter 3 하드웨어와 운영체제

# 메모리

증가한 트랜지스터는 클록 속도를 높이기 위해 쓰였다. 

### 무어의 법칙

```java
대량 생산한 칩상의 트랜지스터 수는 18개월 마다 2배씩 증가한다.
```

자바 언어 또한 컴퓨팅 파워의 향상으로 혜택을 많이 받았지만, 프로그래머로서 가용 리소스를 최대한 활용할 줄 아는 것이 바람직하다.

여기서 클록 속도란?

```java
클럭 속도는 컴퓨터 프로세서의 동작 속도를 나타내는 단위로, CPU가 명령을 얼마나 빠르게 불러오고 
해석하는지를 결정하는 속도
```

**허나 이러한 클록 속도가 증가하였어도 데이터의 속도는 같아 프로세스 코어의 데이터 수요를 메모리가 못 따라가게 되었다.**

![IMG_4349.jpg](img%2FIMG_4349.jpg)

→ 그리하여 고안한 것이 바로 CPU 캐시

CPU 자체에 있는 메모리 영역으로 레지스터보다 느리지만 메인 메모리보다는 빠르다.

⇒ 자주 액세스 하는 메모리 위치는 CPU가 사본으로 관리하자는 제안.

L1, L2 ETC … 이렇듯 많이 참조할 수록 계층번호가 낮다.

일반적으로 L1, L2는 개별로 두고 L3는 일부 혹은 전체 코어가 공유하는 전역 변수처럼 활용.

이러한 개선을 통해 처리율은 개선되었지만 메모리에 있는 데이터를 어떻게 캐시로 가져오고 캐시한 데이터를 어떻게 메모리에 다시 써야할지 결정해야 했다. → 캐시 일관성 프로토콜 

MESI 프로토콜 

- Modified: 데이터가 수정된 상태
- Exclusive: 이 캐시에만 존재하고 메인 메모리 내용과 동일한 상태
- Shared: 둘 이상의 캐시에 데이터가 있으며 메모리 내용과 동일한 상태
- Invalid: 다른 프로세스가 데이터를 수정하여 무효한 상태

|  | M | E | S | I |
| --- | --- | --- | --- | --- |
| M |  |  |  | Y |
| E |  |  |  | Y |
| S |  |  | Y | Y |
| I | Y | Y | Y | Y |

어느 한 프로세서가 배타, 수정 상태로 바뀌면 다른 프로세서는 모두 무효처리 시킨다.

```java
Invalid (I) → Modified (M): 프로세서가 캐시에 없는 데이터를 쓰려고 하면, 캐시가 버스를 통해 데이터를 가져온 후 "Modified" 상태로 변경합니다.

Invalid (I) → Shared (S): 프로세서가 캐시에 없는 데이터를 읽으려고 할 때, 다른 캐시에서 데이터가 존재하거나 메인 메모리에서 가져와 캐시에 저장하고 "Shared" 상태로 변경합니다.

Invalid (I) → Exclusive (E): 프로세서가 캐시에 없는 데이터를 읽으려고 할 때, 해당 데이터가 다른 캐시에 없음을 확인한 후 메인 메모리에서 가져와 캐시에 저장하고 "Exclusive" 상태로 변경합니다.

Exclusive (E) → Modified (M): 프로세서가 "Exclusive" 상태의 데이터를 쓰려고 할 때, "Modified" 상태로 전환됩니다.

Exclusive (E) → Shared (S): 다른 프로세서가 "Exclusive" 상태의 데이터를 읽으려고 할 때, 해당 데이터는 여러 캐시에 존재하게 되어 "Shared" 상태로 변경됩니다.

Shared (S) → Invalid (I): 다른 프로세서가 "Shared" 상태의 데이터를 쓰려고 할 때, 해당 데이터는 무효화되어 "Invalid" 상태로 변경됩니다.

Modified (M) → Shared (S): 다른 프로세서가 "Modified" 상태의 데이터를 읽으려고 할 때, 캐시는 데이터를 메모리에 쓰고 "Shared" 상태로 변경됩니다.

Modified (M) → Invalid (I): 다른 프로세서가 "Modified" 상태의 데이터를 쓰려고 할 때, 해당 캐시 라인은 무효화됩니다.
```

캐시 하드 웨어의 작동원리를 나타낸 가벼운 자바 코드를 보자.

```java
package optimizingjava.chap3;

public class Caching{

    private final int ARR_SIZE = 2 * 1024 * 1024;
    private final int[] testData = new int[ ARR_SIZE ];

    private void run(){
        long warmStart = System.currentTimeMillis();
        System.err.println( "Start: " + warmStart );
        for( int i = 0; i < 15000; i ++ ){
            touchEveryLine();
            touchEveryItem();
        }
        long warmdone = System.currentTimeMillis();
        System.err.println( "Warm up Done: " + warmdone);
        System.err.println( "warm up time == " + ( warmdone - warmStart) );
        System.err.println("Item Line");
        for( int i = 0; i < 100; i ++ ){
            long t0 = System.nanoTime();
            touchEveryLine();
            long t1 = System.nanoTime();
            touchEveryItem();
            long t2 = System.nanoTime();
            long elItem = t2 - t1;
            long elLine = t1 - t0;
            double diff = elItem - elLine;
            System.err.println(elItem+ " " + elLine + " " + ( 100 * diff / elLine ) );
        }
    }
    private void touchEveryItem(){
        for( int i = 0; i < testData.length; i ++ ){
            testData[ i ]++;
        }
    }

    private void touchEveryLine(){
        for( int i = 0; i < testData.length; i += 16 ){
            testData[ i ] ++;
        }
    }

    public static void main(String[] args) {
        Caching c = new Caching();
        c.run();
    }
}
```

**소스 코드만 본다면 touchEveryItem이 Line보다 16배 많은 일을 할 것 같지만 이러한 섣부른 직감은 JVM의 성능 문제를 잘못 판단하기 쉽다는 것이다.**

![IMG_4350.jpg](img%2FIMG_4350.jpg)

가장 지배적인 영향을 미치는 곳은 메모리 버스를 예열하는 부분.

// 실제 소스코드를 돌려보아도 웜업 과정은 4178 그 이후 각 속도 차를 제보면 30내외다.

자바의 성능을 논할 때에는 객체 할당률에 대한 애플리케이션 민감도가 아주 중요하다.

# 최신 프로세서의 특성

## TLB 변환 색인 버퍼

```java
변환 색인 버퍼 TLB는 여러 캐시에서 아주 긴요하게 쓰이는 장치이다. 
가상 메모리 주소를 물리 메모리 주소로 매핑하는 페이지 테이블의 캐시 역할을 수행한다.

TLB가 없다면 L1캐시에 페이지 테이블이 있어도 가상 주소 룩업에 16사이클이나 걸리기에 성능이 잘 안나온다.
```

## 분기 예측과 추측 실행

```java
분기 예측은 최신 프로세서 기법으로 조건 분기하는 기준값을 평가하느라 대기하는 현상을 방지한다.
요즘 프로세서는 다단계 명령 파이프라인을 통해 cpu 1 사이클도 여러 개별 단계로 나누어 실행하기에 동시 실행중일 수도 있다.

이런 모델은 조건문을 다 평가하기 전까지 분기 이후 다음 명령을 알 수 없다는 것이 문제인데, 다단계 파이프라인을
비우는 동안 프로세서는 여러 사이클 동안 멎게된다.

이런일이 발생하지 않도록 프로세서는 트랜지스터를 아낌없이 활용해서 가장 발생 가능성이 큰 브랜치를 미리 결정하는
휴리스틱을 형성한다. -> 도박이라도 한거 마냥 추측결과를 바탕으로 파이프라인을 채움

```

## 하드웨어 메모리 모델

JMM은 프로세서 타입별로 상이한 메모리 액세스 일관성을 고려해서 명시적으로 약한 모델로 설계됬다.

멀티 스레드 코드가 제대로 작동되게 하려면 락과 volatile 을 정확히 알고 써야한다.

# 운영 체제

OS의 주 임무는 여러 실행 프로세스가 공유하는 리소스 액세스를 관장하는 일. 모든 리소스는 한정돼 있고 프로세스는 저마다 리소스를 차지하려고 덤벼들기 때문에 리소스 양을 보고 골고루 나누어 줄 중앙 시스템이 있어야 한다.

한정된 리소스 가운데 메모리와 CPU 시간은 가장 중요한 쌍벽이다.

메모리 관리 유닛 MMU을 통한 가상 주소 방식과 페이지 테이블은 메모리 액세스 제어의 핵심으로서 한 프로세스가 소유한 메모리 영역을 다른 프로세스가 함부로 훼손하지 못하게 만든다.( 앞서 적은 TLB는 이러한 물리 메모리 주소 룩업 시간을 줄이는 하드웨어 기능이다 )

## 프로세스 스케쥴러

CPU 액세스를 통제하는 역할로 실행 큐를 이용한다. 스케줄러는 인터럽트에 응답하고 CPU 코어 액세스를 관리한다. 아래 사진은 자바 스레드의 수명주기를 나타낸 그림이다

![IMG_4351.jpg](img%2FIMG_4351.jpg)

OS 스케줄러는 스레드를 시스템 단일 코어로 분주히 나른다. 

- 스케줄러는 할당 시간 마지막 쯤에 실행 큐로 스레드를 되돌려서 큐의 맨 앞으로 올 때 까지 대기시킨다.

OS는 특성상 CPU에서 코드가 실행되지 않는 시간을 유발한다. 쉽게 간과하기 쉬운 부분으로 실제 프로세스는 실행 큐에 있는 시간이 실행 시간 보다 더 많다는 것.

스케줄러의 움직임을 확인하는 가장 쉬운 방법은 OS가 스케줄링 과정에서 발생시킨 오버헤드를 관측하는 것.

```java
public class Schedulingoverhead {
    public static void main(String[] args) throws InterruptedException {
        long start = System.currentTimeMillis();
        for( int i = 0; i < 1000; i ++ ){
            Thread.sleep(1);
        }
        long end = System.currentTimeMillis();
        System.out.println("Millis elapsed: " + ( end - start ) ); //1263
    }
}

```

단 이 코드의 요점

1. Java의 currentTimeMills()는 OS마다 제공하는 특정 호출을 기반으로 하기에 OS마다 다르게 나옴

### Context Switching

컨텍스트 교환은 OS 스케쥴러가 현재 실행 중인 스레드/태스크를 없애고 대기 중인 다른 스레드/태스크로 교체하는 프로세스이다.

이는 비싼 작업임. 특히 time slice중 유저 모드에서 커널모드로 바뀌면서 기능을 실행해야 할 때가 있는데 이때 매우 비싼 작업이다. 왜냐하면 유저 공간에 있는 코드가 액세스 하는 메모리 영역은 커널 코드와 공유할 부분이 없기에 모드가 바뀌면 명령어와 다른 캐시를 강제로 비워야 한다.

```java
타임 슬라이스란?
CPU 할당: 운영체제의 스케줄러는 대기 중인 프로세스(또는 스레드) 중 하나를 선택하여 CPU를 할당한다.
정해진 시간 동안 실행: 프로세스는 타임 슬라이스 동안 CPU에서 실행됩니다. 이 시간 동안 프로세스는 가능한 많은 작업을 수행한다.
타임 슬라이스 종료 후:
만약 프로세스가 타임 슬라이스가 끝나기 전에 작업을 완료하면, 프로세스는 CPU를 반납하고 다른 프로세스가 CPU를 사용할 수 있도록 한다.
프로세스가 타임 슬라이스 동안 작업을 완료하지 못하면, CPU는 다른 프로세스로 전환됩니다. 

위 글의 내용은 프로세스가 CPU를 점유하고 있는 동안 커널에 있는 특정 기능을 실행해야 하는 경우를 뜻하는
것 같다.
```

리눅스는 이를 만회하기 위해 vDSO라는 객체를 제공한다.

### 가상 동적 공유 객체 ( Virtual Dynamically Shared Object )

```java
커널 권한이 필요 없는 시스템 콜의 속도를 높이고자 쓰는 유저 메모리 영역
예를 들어 gettimeofday()는 굳이 side effect를 발생시키지 않기 때문에 커널 privileged access
가 필요 없다.
```

**자바에서도 타이밍 자료등은 이를 활용하여 성능을 끌어올릴 수 있다.**

# 단순 시스템 모델

단순한 시스템 모델로 성능 문제를 일으키는 원인을 알아보자.

유닉스 계열 OS에서 자바는 아래와 같은 컴포넌트 기반에서 작동한다

- 애플리케이션이 실행되는 하드웨어와 OS
- 애플리케이션이 실행되는 JVM/컨테이너
- 애플리케이션 코드
- 애플리케이션이 불러오는 외부 시스템
  - 유입 트래픽
    
    ![IMG_4352.jpg](img%2FIMG_4352.jpg)
    

위 사진의 어떤 요소든지 성능 저하를 일으킬 수 있다. 누가 진범인지 찾는 방법을 알아보자

## 기본 감지 전략

1. 애플리케이션이 잘 돌아간다는 것은 CPU 사용량, 메모리, 네트워크 ,IO 대역폭 등을 통해 체크 가능하다.
2. 즉 리소스 한계에 다다랐는지 각 영역에 대해 조사하고 이를 알아보자

### CPU 사용률

CPU 사용률은 애플리케이션 성능을 나타내는 핵심 지표이다. CPU 사이클은 애플리케이션이 가장 갈증을 느끼는 리소스이기에 부하가 심할 때 사용률이 100%에 가까워야 바람직하다.

vmstat과 iostat에 대해 알아두자.

### vmstat

![IMG_4353.jpg](img%2FIMG_4353.jpg)

procs → 실행 가능 r / 블로킹 b 프로세스의 개수를 나타냄

memory → 스왑 메모리, 미사용 메모리, 버퍼 사용 메모리, 캐시 사용 메모리가 잇따라 표시됨.

swap → 디스크로 교체되어 들어간 메모리 si, 디스크에서 교체되어 빠져나온 메모리 so

io → 블록-인, 블록-아웃 개수 // 블록(I/O)장치에서 주고 받은 512바이트 블록 개수

system → 인터럽트( in ) 및 초당 컨텍스트 스위칭 횟수 ( cs )

cpu → cpu 연관 지표 사용률을 %로 표기 유저 시간( us ), 커널 시간( sy ), 유휴 시간( id ), 대기시간( wa ), 도둑 맞은 시간( st )

계산을 많이 하는 워크로드는 유저 공간의 cPU 사용률을 100에 가깝게 유지하는 것이 목표이다.

⇒ 유저 공간에서 CPU 사용률이 100% 근처도 못갔는데 어떤 프로세스에서 컨텍스트 스위칭 비율이 높게 나타나면 I/O 블로킹이 문제거나 스레드 락 경합이 벌어졌을 가능성이 크다.

<aside>
💡

### . I/O 블로킹 (I/O Blocking)

- I/O 블로킹은 **프로세스나 스레드가 입출력 작업을 수행하는 동안 CPU가 대기** 상태에 빠지는 것을 의미.
- 예를 들어, 파일 읽기/쓰기, 네트워크 통신, 데이터베이스 접근과 같은 작업은 상대적으로 시간이 오래 걸리기 때문에, CPU가 이 작업을 기다리면서 다른 일을 하지 못하고 대기.
- 이로 인해, 해당 프로세스가 CPU를 계속 사용하지 않고 대기하는 동안 CPU의 사용률은 떨어지게 됩니다. **멀티스레딩**이나 **비동기 처리**를 통해 다른 작업을 동시에 수행하지 않는 한, CPU는 이 I/O 작업이 완료될 때까지 유휴 상태가 된다.

### 2. 스레드 락 경합 (Thread Lock Contention)

- 락 경합은 여러 스레드가 **동시에 공유 자원에 접근하려고 할 때 락을 얻기 위해 대기**하면서 발생합니다.
- 스레드가 락을 얻기 위해 대기하는 동안 CPU는 이 스레드를 실행하지 못하고, 다른 스레드를 실행하게 되거나 유휴 상태로 남게 된다. 이때 스레드는 CPU를 사용할 수 있는 상태가 아니므로, 시스템 전체의 CPU 사용률은 떨어질 수 있습니다.
- 특히, 뮤텍스(Mutex)와 같은 락을 사용하여 **임계 구역**을 보호할 때 경합이 심해지면, 스레드들이 락을 얻기 위해 오랫동안 대기할 수 있으며, 이는 CPU가 완전히 활용되지 않는 원인이 됩니다.
</aside>

### 가비지 수집

핫스팟 JVM은 시작 시 메모리를 유저 공간에 할당하고 관리한다. 즉 시스템 콜을 통해 메모리를 할당하지 않기에 가비지 수집을 하려고 커널 교환을 할 일이 없다. 

→ 대부분 GC는 시간 소비의 주범이 아니다. 유저 공간의 CPU 사이클을 소비하되 커널 공간의 사용률에 영향을 미치지 않기 때문.

→ 허나 어떤 jvm 프로세스가 유저 공간에서 CPU를 100% 가까이 쓴다면 이는 GC일 확률이 높다.

자세한 내용은 7장 GC 로그 챕터에서 다룬다.

### 입출력

파일 I/O는 예로부터 전체 시스템에 좋지 못한 영향을 주는 존재였다. 자바 프로그램은 단순한 I/O만 처리하고 I/O 서브 시스템을 심하게 가동하는 애플리케이션 클래스도 적은 편이다. 또 CPU, 메모리 어느 한쪽과 I/O를 동시에 고갈시킬 애플리케이션은 거의 없다.

### 커널 바이패스 I/O

커널을 이용해 데이터를 복사해 유저 공간에 넣는 작업이 상당히 비싼 고성능 애플리케이션들이 사용하는 방법

<aside>
💡

- 커널 바이패스 I/O(Kernel Bypass I/O)는 **애플리케이션이 커널을 거치지 않고 직접 하드웨어(특히 네트워크나 스토리지 장치)에 접근하여 I/O 작업을 수행하는 방법**입니다. 이는 전통적인 I/O 방식에서 발생하는 **커널 오버헤드**와 **컨텍스트 스위칭**을 줄여 **성능을 크게 향상**시키기 위해 사용됩니다.

### 전통적인 I/O 방식의 문제점

- **커널을 통한 접근**: 일반적인 I/O 작업은 애플리케이션이 시스템 콜을 통해 커널에 요청하고, 커널이 하드웨어를 제어하여 데이터를 주고받습니다.
- **오버헤드**: 커널을 경유하면서 컨텍스트 스위칭, 버퍼 복사, 인터럽트 처리 등의 오버헤드가 발생해 성능이 저하됩니다. 특히 네트워크와 같은 고속 I/O 장치의 경우, 이런 오버헤드가 병목이 되어 성능이 제한될 수 있습니다.

### 커널 바이패스 I/O의 동작 방식

- **직접 하드웨어 접근**: 커널 바이패스 I/O는 애플리케이션이 커널의 개입 없이 **직접 하드웨어와 통신**할 수 있도록 지원합니다. 이를 위해 하드웨어 장치와 애플리케이션 사이에 **사용자 공간 라이브러리**를 사용하거나, 하드웨어가 직접 애플리케이션의 메모리와 상호작용할 수 있는 메커니즘을 제공합니다.
- **메모리 맵핑**: 애플리케이션이 하드웨어의 **DMA(Direct Memory Access)**를 이용해 메모리 공간을 직접 장치에 매핑하여 데이터를 주고받습니다. 이를 통해 커널이 개입할 필요가 없어지고, 데이터 복사와 컨텍스트 스위칭 오버헤드가 줄어듭니다.
</aside>

# 가상화

- 비가상화 시스템에서는 OS 커널은 프리빌리지드 모드로 동작하여 하드웨어에 접근 가능
- 가상화 시스템은 게스트 OS가 하드웨어에 직접 액세스 불가
    - 언프리빌리지드 명령어로 고쳐서 씀

<aside>
💡

JVM은 자바 코드에 공용 인터페이스를 제공해서 OS에 독립적인 휴대용 실행 환경을 제공한다. 스레드 스케쥴링 같은 기본적인 서비스조차 하부 OS에 반드시 액세스 해야하는데, 이런 기능은 native 키워드를 붙여서 네이티브 메소드로 구현된다. 이는 C언어로 구성되어 있고, 여느 자바 메서드 처럼 액세스 가능하다. 그리고 이걸 대행하는 공통 인터페이스를 자바 네이티브 인터페이스 ( **JNI** ) 라고 부른다

</aside>